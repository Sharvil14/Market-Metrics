{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy PyPDF2 sentence-transformers chromadb colorama pandas tabulate"
      ],
      "metadata": {
        "id": "8TMNFprGZmKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21c6ca1-7a9c-4a02-b29c-8dcdf041b6a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Collecting PyPDF2\n",
            "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting colorama\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Using cached pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Using cached onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=6ff0370308eceac4e860cb60d50cf3655af13e1247302c19643a784afb3adc3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, PyPDF2, pybase64, mmh3, humanfriendly, httptools, colorama, bcrypt, backoff, watchfiles, coloredlogs, posthog, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.1 colorama-0.4.6 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from typing import List, Dict, Tuple\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "import PyPDF2\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from google.colab import files\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "OaPgq9SkZsb4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to import colorama for colored output\n",
        "try:\n",
        "    from colorama import init, Fore, Style\n",
        "    init(autoreset=True)\n",
        "    COLORS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    COLORS_AVAILABLE = False\n",
        "    class Fore:\n",
        "        GREEN = CYAN = YELLOW = RED = MAGENTA = BLUE = WHITE = \"\"\n",
        "    class Style:\n",
        "        BRIGHT = RESET_ALL = \"\"\n",
        "\n",
        "class ProductComparator:\n",
        "    \"\"\"\n",
        "    A RAG-based chatbot to compare product features from uploaded brochures.\n",
        "    Accepts queries like: \"Compare battery and camera of iPhone vs Samsung\"\n",
        "    Outputs a clean comparison table.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pdf_folder: str):\n",
        "        self.pdf_folder = pdf_folder\n",
        "        self.products = []  # List of {name, chunks}\n",
        "        self.embedding_model = None\n",
        "        self.collection = None\n",
        "        self.client = None\n",
        "\n",
        "        # Customize these based on your domain (phones, laptops, cars, etc.)\n",
        "        self.feature_keywords = [\n",
        "            'display', 'screen', 'battery', 'camera', 'processor', 'cpu', 'chip',\n",
        "            'ram', 'memory', 'storage', 'price', 'cost', 'weight', 'dimensions',\n",
        "            'os', 'operating system', 'connectivity', 'wifi', 'bluetooth', '5g',\n",
        "            'warranty', 'color', 'material', 'water resistance', 'audio', 'speakers',\n",
        "            'sensors', 'security', 'face id', 'fingerprint', 'charging', 'fast charge'\n",
        "        ]\n",
        "\n",
        "    def _extract_text_from_pdf(self, path: str) -> str:\n",
        "        \"\"\"Extract raw text from a PDF file.\"\"\"\n",
        "        try:\n",
        "            with open(path, 'rb') as f:\n",
        "                reader = PyPDF2.PdfReader(f)\n",
        "                text = \"\"\n",
        "                for page in reader.pages:\n",
        "                    text += page.extract_text() or \"\"\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            print(f\"{Fore.RED}❌ Failed to read {path}: {e}{Style.RESET_ALL}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _chunk_by_features(self, text: str, product_name: str) -> List[Dict]:\n",
        "        \"\"\"Split brochure text into feature-based chunks.\"\"\"\n",
        "        chunks = []\n",
        "        lines = text.split('\\n')\n",
        "        current_feature = \"General\"\n",
        "        current_content = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            line_clean = line.strip()\n",
        "            if not line_clean:\n",
        "                continue\n",
        "\n",
        "            # Detect feature headers (case-insensitive, short lines)\n",
        "            matched_feature = None\n",
        "            for feat in self.feature_keywords:\n",
        "                if feat in line_clean.lower() and len(line_clean) < 80:\n",
        "                    matched_feature = feat.title()\n",
        "                    break\n",
        "\n",
        "            if matched_feature:\n",
        "                if current_content.strip():\n",
        "                    chunks.append({\n",
        "                        'product': product_name,\n",
        "                        'feature': current_feature,\n",
        "                        'content': current_content.strip()\n",
        "                    })\n",
        "                current_feature = matched_feature\n",
        "                current_content = line_clean + \"\\n\"\n",
        "            else:\n",
        "                current_content += line_clean + \"\\n\"\n",
        "\n",
        "        if current_content.strip():\n",
        "            chunks.append({\n",
        "                'product': product_name,\n",
        "                'feature': current_feature,\n",
        "                'content': current_content.strip()\n",
        "            })\n",
        "        return chunks\n",
        "\n",
        "    def load_all_pdfs(self):\n",
        "        \"\"\"Load all PDFs from folder and chunk by features.\"\"\"\n",
        "        print(f\"{Fore.CYAN}📂 Loading product brochures from: {self.pdf_folder}{Style.RESET_ALL}\")\n",
        "        if not os.path.exists(self.pdf_folder):\n",
        "            raise FileNotFoundError(f\"Folder not found: {self.pdf_folder}\")\n",
        "\n",
        "        pdf_files = [f for f in os.listdir(self.pdf_folder) if f.lower().endswith('.pdf')]\n",
        "        if not pdf_files:\n",
        "            raise FileNotFoundError(\"No PDF files found in the folder!\")\n",
        "\n",
        "        for pdf_file in pdf_files:\n",
        "            product_name = os.path.splitext(pdf_file)[0].replace('_', ' ').replace('-', ' ').title()\n",
        "            full_path = os.path.join(self.pdf_folder, pdf_file)\n",
        "            text = self._extract_text_from_pdf(full_path)\n",
        "            if not text.strip():\n",
        "                print(f\"{Fore.YELLOW}⚠️  Skipping empty PDF: {pdf_file}{Style.RESET_ALL}\")\n",
        "                continue\n",
        "            chunks = self._chunk_by_features(text, product_name)\n",
        "            self.products.append({'name': product_name, 'chunks': chunks})\n",
        "            print(f\"  ✅ Loaded: {product_name} ({len(chunks)} chunks)\")\n",
        "\n",
        "    def build_vector_store(self):\n",
        "        \"\"\"Build ChromaDB vector store with metadata.\"\"\"\n",
        "        print(f\"{Fore.CYAN}🧠 Loading embedding model...{Style.RESET_ALL}\")\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        print(f\"{Fore.CYAN}💾 Building vector database...{Style.RESET_ALL}\")\n",
        "        self.client = chromadb.Client()\n",
        "        self.collection = self.client.create_collection(\"product_specs\")\n",
        "\n",
        "        all_docs, all_metadatas, all_ids = [], [], []\n",
        "        chunk_id = 0\n",
        "\n",
        "        for product in self.products:\n",
        "            for chunk in product['chunks']:\n",
        "                all_docs.append(chunk['content'])\n",
        "                all_metadatas.append({\n",
        "                    'product': chunk['product'],\n",
        "                    'feature': chunk['feature']\n",
        "                })\n",
        "                all_ids.append(f\"chunk_{chunk_id}\")\n",
        "                chunk_id += 1\n",
        "\n",
        "        embeddings = self.embedding_model.encode(all_docs, show_progress_bar=False)\n",
        "        self.collection.add(\n",
        "            embeddings=embeddings.tolist(),\n",
        "            documents=all_docs,\n",
        "            metadatas=all_metadatas,\n",
        "            ids=all_ids\n",
        "        )\n",
        "        print(f\"{Fore.GREEN}✅ Database ready with {len(all_docs)} chunks{Style.RESET_ALL}\")\n",
        "\n",
        "    def is_comparison_query(self, query: str) -> bool:\n",
        "        return any(word in query.lower() for word in ['compare', 'vs', 'versus', 'difference'])\n",
        "\n",
        "    def extract_features_from_query(self, query: str) -> List[str]:\n",
        "        \"\"\"Extract relevant features mentioned in the query.\"\"\"\n",
        "        found = []\n",
        "        query_lower = query.lower()\n",
        "        for feat in self.feature_keywords:\n",
        "            if feat in query_lower:\n",
        "                # Use canonical name (first word)\n",
        "                found.append(feat.split()[0].title())\n",
        "        return list(dict.fromkeys(found))  # dedupe\n",
        "\n",
        "    def retrieve_feature_value(self, product: str, feature: str) -> str:\n",
        "        \"\"\"Retrieve and clean the best value for a (product, feature) pair.\"\"\"\n",
        "        results = self.collection.query(\n",
        "            query_texts=[f\"{product} {feature} specifications\"],\n",
        "            n_results=1,\n",
        "            where={\"product\": product, \"feature\": feature}\n",
        "        )\n",
        "        if results['documents'][0]:\n",
        "            text = results['documents'][0][0]\n",
        "            # Try to extract concise value: look for numbers + units\n",
        "            match = re.search(r'(\\d+\\.?\\d*\\s*[a-zA-Z%]+(?:\\s*/\\s*\\w+)?)', text)\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "            # Fallback: first 60 chars\n",
        "            return (text[:60] + \"...\") if len(text) > 60 else text\n",
        "        return \"Not found\"\n",
        "\n",
        "    def generate_comparison_table(self, query: str) -> str:\n",
        "        \"\"\"Generate a markdown-style comparison table.\"\"\"\n",
        "        product_names = [p['name'] for p in self.products]\n",
        "        features = self.extract_features_from_query(query)\n",
        "\n",
        "        if not features:\n",
        "            # Default to top common features if none specified\n",
        "            features = ['Battery', 'Display', 'Camera', 'Processor', 'Price']\n",
        "\n",
        "        data = {\"Feature\": features}\n",
        "        for product in product_names:\n",
        "            values = []\n",
        "            for feat in features:\n",
        "                val = self.retrieve_feature_value(product, feat)\n",
        "                values.append(val)\n",
        "            data[product] = values\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        return tabulate(df, headers='keys', tablefmt='grid', showindex=False)\n",
        "\n",
        "    def setup(self) -> bool:\n",
        "        \"\"\"Full setup: load PDFs + build DB.\"\"\"\n",
        "        print(f\"\\n{Fore.CYAN}{Style.BRIGHT}╔{'═'*78}╗{Style.RESET_ALL}\")\n",
        "        print(f\"{Fore.CYAN}{Style.BRIGHT}║{' '*18}🔍 COMPETITOR PRODUCT COMPARATOR{' '*22}║{Style.RESET_ALL}\")\n",
        "        print(f\"{Fore.CYAN}{Style.BRIGHT}╚{'═'*78}╝{Style.RESET_ALL}\\n\")\n",
        "        try:\n",
        "            self.load_all_pdfs()\n",
        "            self.build_vector_store()\n",
        "            print(f\"\\n{Fore.GREEN}{Style.BRIGHT}┌{'─'*78}┐{Style.RESET_ALL}\")\n",
        "            print(f\"{Fore.GREEN}│  ✅ Ready! Ask: 'Compare battery and camera of ProductA vs ProductB'{' '*5}│{Style.RESET_ALL}\")\n",
        "            print(f\"{Fore.MAGENTA}│  🚪 Type 'quit' or 'exit' to stop{' '*45}│{Style.RESET_ALL}\")\n",
        "            print(f\"{Fore.GREEN}{Style.BRIGHT}└{'─'*78}┘{Style.RESET_ALL}\\n\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"{Fore.RED}❌ Setup failed: {e}{Style.RESET_ALL}\")\n",
        "            return False\n",
        "\n",
        "    def chat(self):\n",
        "        \"\"\"Interactive chat loop.\"\"\"\n",
        "        while True:\n",
        "            try:\n",
        "                query = input(f\"{Fore.CYAN}{Style.BRIGHT}💬 You: {Style.RESET_ALL}\").strip()\n",
        "                if query.lower() in ['quit', 'exit', 'bye']:\n",
        "                    print(f\"\\n{Fore.MAGENTA}👋 Goodbye! Thanks for comparing!{Style.RESET_ALL}\\n\")\n",
        "                    break\n",
        "                if not query:\n",
        "                    continue\n",
        "\n",
        "                if self.is_comparison_query(query):\n",
        "                    table = self.generate_comparison_table(query)\n",
        "                    print(f\"\\n{Fore.YELLOW}📊 Comparison Result:\\n{Style.RESET_ALL}\")\n",
        "                    print(table)\n",
        "                    print()\n",
        "                else:\n",
        "                    print(f\"{Fore.RED}⚠️ Please ask a comparison question (e.g., 'Compare battery of X vs Y'){Style.RESET_ALL}\\n\")\n",
        "            except KeyboardInterrupt:\n",
        "                print(f\"\\n{Fore.MAGENTA}👋 Session ended.{Style.RESET_ALL}\\n\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"{Fore.RED}❌ Error: {e}{Style.RESET_ALL}\\n\")"
      ],
      "metadata": {
        "id": "rO--s_ByY5tc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # 👇 This section now handles file uploads\n",
        "\n",
        "    print(f\"{Fore.CYAN}Please upload your product brochures (PDFs):{Style.RESET_ALL}\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    temp_pdf_folder = \"/content/uploaded_brochures\"\n",
        "    os.makedirs(temp_pdf_folder, exist_ok=True)\n",
        "\n",
        "    # Save uploaded files to the temporary folder\n",
        "    for fn, content in uploaded.items():\n",
        "      print(f'Saving \"{fn}\"...')\n",
        "      with open(os.path.join(temp_pdf_folder, fn), 'wb') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    # Update the PDF_FOLDER variable to the temporary folder\n",
        "    PDF_FOLDER = temp_pdf_folder\n",
        "\n",
        "    print(f\"\\nUploaded files saved to: {PDF_FOLDER}\")\n",
        "\n",
        "    # Now proceed with the rest of the setup using the uploaded files\n",
        "    comparator = ProductComparator(PDF_FOLDER)\n",
        "    if comparator.setup():\n",
        "        comparator.chat()\n",
        "    else:\n",
        "        print(f\"\\n{Fore.RED}⚠️  Initialization failed. Check uploaded files and PDFs.{Style.RESET_ALL}\")"
      ],
      "metadata": {
        "id": "p4dkzzwjY6Os",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "8b7d77bd-fba1-4614-81c9-e0f97c5f9393"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your product brochures (PDFs):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cfc0b169-2e27-4fe0-99b5-824f5221e00d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cfc0b169-2e27-4fe0-99b5-824f5221e00d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BMW-Serie-3-2008-CN.pdf to BMW-Serie-3-2008-CN.pdf\n",
            "Saving GMC-MotorHome-1973-USA.pdf to GMC-MotorHome-1973-USA.pdf\n",
            "Saving \"BMW-Serie-3-2008-CN.pdf\"...\n",
            "Saving \"GMC-MotorHome-1973-USA.pdf\"...\n",
            "\n",
            "Uploaded files saved to: /content/uploaded_brochures\n",
            "\n",
            "╔══════════════════════════════════════════════════════════════════════════════╗\n",
            "║                  🔍 COMPETITOR PRODUCT COMPARATOR                      ║\n",
            "╚══════════════════════════════════════════════════════════════════════════════╝\n",
            "\n",
            "📂 Loading product brochures from: /content/uploaded_brochures\n",
            "  ✅ Loaded: Bmw Serie 3 2008 Cn (1 chunks)\n",
            "⚠️  Skipping empty PDF: GMC-MotorHome-1973-USA.pdf\n",
            "🧠 Loading embedding model...\n",
            "💾 Building vector database...\n",
            "✅ Database ready with 1 chunks\n",
            "\n",
            "┌──────────────────────────────────────────────────────────────────────────────┐\n",
            "│  ✅ Ready! Ask: 'Compare battery and camera of ProductA vs ProductB'     │\n",
            "│  🚪 Type 'quit' or 'exit' to stop                                             │\n",
            "└──────────────────────────────────────────────────────────────────────────────┘\n",
            "\n",
            "\u001b[36m\u001b[1m💬 You: \u001b[0mprovide me business insights\n",
            "⚠️ Please ask a comparison question (e.g., 'Compare battery of X vs Y')\n",
            "\n",
            "\u001b[36m\u001b[1m💬 You: \u001b[0mCompare battery and camera of ProductA vs ProductB\n",
            "❌ Error: Expected where to have exactly one operator, got {'product': 'Bmw Serie 3 2008 Cn', 'feature': 'Battery'} in query.\n",
            "\n",
            "\n",
            "👋 Session ended.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DeCqJiifa88A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}